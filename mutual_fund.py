# -*- coding: utf-8 -*-
"""Mutual Fund.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dV4FFG4tKlh7FJhWYkGC8MEGse1VoTB_
"""

# Importing the required libraries
!pip urllib
import urllib
import requests
import pandas as pd
from bs4 import BeautifulSoup


mf_info = []
      database_mf_info = []
      category_name = ""
      mf_name = ""

mf_name_full = soup.find("h1", {"class": "page_heading navdetails_heading"}).get_text()
mf_name_full = mf_name_full.partition('-')
mf_name_req = mf_name_full[0]
print(mf_name_req)
database_mf_info.append(mf_name_req)

       
cat_full_name = soup.find("span", {"class": "hidden-xs hidden-sm"}).get_text()
cat_name = cat_full_name[:-2]
print(cat_name)
database_mf_info.append(cat_name)


# Downloading contents of the web page
url = "https://www.valueresearchonline.com/funds/15831/aditya-birla-sun-life-frontline-equity-fund-direct-plan"
data = requests.get(url).text


# Creating BeautifulSoup object
soup = BeautifulSoup(data, 'html.parser')

# Verifying tables and their id
print("ID of each table:")
for table in soup.find_all('table'):
    print(table.get('id'))

# Creating list with all tables
tables = soup.find_all('table')

#  Looking for the table with the id 'peer comparison table'
table1 = soup.find('table', id='peer-comparison-table')


# Defining of the dataframe
df1 = pd.DataFrame(columns=['Rating', 'Launch-date', '1 yr return', '3 yr return', '5 yr return', 'Expense Ratio', 'Assets'])

# Collecting Ddata
for row in table1.tbody.find_all('tr'):    
    # Find all data for each column
    columns = row.find('td')
    if(columns != []):
        rating = columns[0].text.strip()
        launch = columns[1].span.contents[0].strip('&0')
        first = columns[2].span.contents[0].strip('&0.')
        third = columns[3].span.contents[0].strip('&0.')
        fifth = columns[4].span.contents[0].strip('&0.')
        er = columns[5].span.contents[0].strip('&0.')
        asset = columns[6].span.contents[0].strip('&0.')


df1 = df1.append({'Rating': rating,  'Launch-date': launch, '1 yr return': first, '3 yr return': third, '5 yr return': fifth, 'Expense Ratio': er, 'Assets': asset}, ignore_index=True)
df1.head()


#  Looking for the table with the id 'risk-measures-percentage'
table2 = soup.find('table', id='risk-measures-percentage')


# Defining of the dataframe
df2 = pd.DataFrame(columns=['Mean', 'Std Dev', 'Sharpe', 'Sortino', 'Beta', 'Alpha'])

# Collecting Ddata
for row in table2.tbody.find_all('tr'):    
    # Find all data for each column
    columns = row.find('td')
    if(columns != []):
        mean = columns[0].span.contents[0].strip('&0')
        stddev = columns[1].span.contents[0].strip('&0')
        sharpe = columns[2].span.contents[0].strip('&0.')
        sortino = columns[3].span.contents[0].strip('&0.')
        beta = columns[4].span.contents[0].strip('&0.')
        alpha = columns[5].span.contents[0].strip('&0.')
        

df2 = df2.append({'Mean': mean,  'Std Dev': stddev, 'Sharpe': sharpe, 'Sortino': sortino, 'Beta': beta, 'Alpha': alpha}, ignore_index=True)
df2.head()


mf_info.append(rating)
mf_info.append(launch)
mf_info.append(first)
mf_info.append(third)
mf_info.append(fifth)
mf_info.append(er)
mf_info.append(asset)
mf_info.append(mean)
mf_info.append(stddev)
mf_info.append(sharpe)
mf_info.append(sortino)
mf_info.append(beta)
mf_info.append(alpha)


all_mfs_info.append(mf_info)
      database_all_mf_info.append(database_mf_info)
  print(database_all_mf_info)

  return all_mfs_info

